{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-training static quantization (Pytorch) - ResNet18\n",
    "In this notebook, you will be able to see how quantization in PyTorch can result in significant decreases in model size while increasing speed. Note that quantization is currently only supported for CPUs, so we will be utilizing GPUs / CUDA only for training and CPU for testing.\n",
    "Furthermore, while using complex dataset the accuracy might decrease upon quantization. By using a quantization configuration\n",
    "\n",
    "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "we can significantly improve on the accuracy. We repeat the same exercise with the recommended configuration for quantizing for x86 architectures. This configuration does the following:\n",
    "1. Quantizes weights on a per-channel basis\n",
    "2. Uses a histogram observer that collects a histogram of activations and then picks quantization parameters in an optimal manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "               batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(torchvision.datasets.MNIST('../data', train=False, \n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "              batch_size=64, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 model\n",
    "This code is taken from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py \n",
    "\n",
    "> NOTE: Training uses resnet model as is with addition operation and floating point inputs / outputs.      \n",
    "But when model is quantized while testing addition operation is replaced with FloatFunction and the inputs         / outputs are quantized/dequantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        groups: Number of blocked connections from input channels to output channels. Default: 1\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=3, with specified out_planes\n",
    "    \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=1, with specified out_planes\n",
    "        \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, quantize=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Notice the addition operation in both scenarios\n",
    "        if self.quantize:\n",
    "            out = self.skip_add.add(out, identity)\n",
    "        else:\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, mnist=False, quantize=False, batchnorm=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if mnist:\n",
    "            num_channels = 1\n",
    "        else:\n",
    "            num_channels = 3\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace \n",
    "            # the 2x2 stride with a dilated convolution instead.\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        \n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer, quantize=self.quantize))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer, quantize=self.quantize))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # Input are quantized\n",
    "        if self.quantize:\n",
    "            x = self.quant(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        if self.batchnorm:\n",
    "            x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Outputs are dequantized\n",
    "        if self.quantize:\n",
    "            x = self.dequant(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "         # See note [TorchScript super()]\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\" Train the model with given dataset\n",
    "    \n",
    "    Args:\n",
    "        args: args like log interval\n",
    "        model: ResNet model to train\n",
    "        device: CPU/GPU\n",
    "        train_loader: dataset iterator\n",
    "        optimizer: optimizer to update weights\n",
    "        epoch: number of epochs to train for\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=-1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.695870\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.163330\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    " \n",
    "    batch_size = 64\n",
    "    epochs = 1\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 500\n",
    "    save_model = True\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = ResNet(num_classes=10, mnist=True).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.ckpt\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Print the size of the model.\n",
    "    \n",
    "    Args:\n",
    "        model: model whose size needs to be determined\n",
    "\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_model(model, device, quantize=False, save=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing with qauntization if quantize=True\n",
    "    if quantize:\n",
    "        modules_to_fuse = [['conv1', 'bn1'],\n",
    "                   ['layer1.0.conv1', 'layer1.0.bn1'],\n",
    "                   ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "                   ['layer1.1.conv1', 'layer1.1.bn1'],\n",
    "                   ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "                   ['layer2.0.conv1', 'layer2.0.bn1'],\n",
    "                   ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "                   ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
    "                   ['layer2.1.conv1', 'layer2.1.bn1'],\n",
    "                   ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "                   ['layer3.0.conv1', 'layer3.0.bn1'],\n",
    "                   ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "                   ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
    "                   ['layer3.1.conv1', 'layer3.1.bn1'],\n",
    "                   ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "                   ['layer4.0.conv1', 'layer4.0.bn1'],\n",
    "                   ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "                   ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
    "                   ['layer4.1.conv1', 'layer4.1.bn1'],\n",
    "                   ['layer4.1.conv2', 'layer4.1.bn2']]\n",
    "        model = torch.quantization.fuse_modules(model, modules_to_fuse)\n",
    "        \n",
    "        model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        \n",
    "        torch.quantization.prepare(model, inplace=True)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                model(data)\n",
    "        \n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "        \n",
    "        if save:\n",
    "            # torch.save(model.state_dict(), \"mnist_cnn_qint8.ckpt\")\n",
    "            torch.jit.save(torch.jit.script(model), \"mnist_cnn_qint8.ckpt\")\n",
    "            return model\n",
    "        else:\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " def test_evaluate(model, device, test_loader):\n",
    "    print(model)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            st = time.time()\n",
    "            output = model(data)\n",
    "            et = time.time()\n",
    "            test_loss += F.nll_loss(F.log_softmax(output, dim=-1), target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance - unquantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 44.778637\n",
      "\n",
      "Test set: Average loss: 0.0604, Accuracy: 9810/10000 (98%)\n",
      "\n",
      "Elapsed time = 13.0780 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "# instantiate and load unquantized model\n",
    "encoder = ResNet(num_classes=10, mnist=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.ckpt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "\n",
    "# run evaluation on this unquantized model\n",
    "test_evaluate(model=encoder, device=device, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=ResNet\n",
      "  (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "  (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "  (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "  (maxpool): RecursiveScriptModule(original_name=MaxPool2d)\n",
      "  (layer1): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "      (skip_add): RecursiveScriptModule(\n",
      "        original_name=QFunctional\n",
      "        (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "    )\n",
      "    (1): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "      (skip_add): RecursiveScriptModule(\n",
      "        original_name=QFunctional\n",
      "        (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "      (downsample): RecursiveScriptModule(\n",
      "        original_name=Sequential\n",
      "        (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (1): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "      (skip_add): RecursiveScriptModule(\n",
      "        original_name=QFunctional\n",
      "        (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "    )\n",
      "    (1): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "      (skip_add): RecursiveScriptModule(\n",
      "        original_name=QFunctional\n",
      "        (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "      (downsample): RecursiveScriptModule(\n",
      "        original_name=Sequential\n",
      "        (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (1): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "      (skip_add): RecursiveScriptModule(\n",
      "        original_name=QFunctional\n",
      "        (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "    )\n",
      "    (1): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "      (skip_add): RecursiveScriptModule(\n",
      "        original_name=QFunctional\n",
      "        (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): RecursiveScriptModule(\n",
      "    original_name=Sequential\n",
      "    (0): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "      (downsample): RecursiveScriptModule(\n",
      "        original_name=Sequential\n",
      "        (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (1): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "      (skip_add): RecursiveScriptModule(\n",
      "        original_name=QFunctional\n",
      "        (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "    )\n",
      "    (1): RecursiveScriptModule(\n",
      "      original_name=BasicBlock\n",
      "      (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "      (relu): RecursiveScriptModule(original_name=ReLU)\n",
      "      (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "      (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "      (skip_add): RecursiveScriptModule(\n",
      "        original_name=QFunctional\n",
      "        (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): RecursiveScriptModule(original_name=AdaptiveAvgPool2d)\n",
      "  (fc): RecursiveScriptModule(\n",
      "    original_name=Linear\n",
      "    (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n",
      "  )\n",
      "  (quant): RecursiveScriptModule(original_name=Quantize)\n",
      "  (dequant): RecursiveScriptModule(original_name=DeQuantize)\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 0.003687\n",
      "\n",
      "Test set: Average loss: 0.0528, Accuracy: 9832/10000 (98%)\n",
      "\n",
      "Elapsed time = 3.5536 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "# instantiate and load unquantized model \n",
    "encoder_unquant = ResNet(num_classes=10, mnist=True, quantize=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.ckpt', map_location=device)\n",
    "encoder_unquant.load_state_dict(loaded_dict_enc)\n",
    "\n",
    "# convert unquantized model to quantized form\n",
    "encoder = quantize_model(model=encoder_unquant, device=device, quantize=True, save=True)\n",
    "\n",
    "# load the saved quantized model\n",
    "encoder = torch.jit.load(\"mnist_cnn_qint8.ckpt\")\n",
    "# encoder = ResNet(num_classes=10, mnist=True, quantize=True)\n",
    "# loaded_quant_dict = torch.load(\"mnist_cnn_qint8.ckpt\", map_location=device)\n",
    "# encoder.load_state_dict(loaded_quant_dict)\n",
    "\n",
    "# run evaluation on this quantized model \n",
    "test_evaluate(model=encoder, device=device, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
