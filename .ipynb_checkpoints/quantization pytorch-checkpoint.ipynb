{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-training static quantization (Pytorch) - ResNet18\n",
    "In this notebook, you will be able to see how quantization in PyTorch can result in significant decreases in model size while increasing speed. Note that quantization is currently only supported for CPUs, so we will be utilizing GPUs / CUDA only for training and CPU for testing.\n",
    "Furthermore, while using complex dataset the accuracy might decrease upon quantization. By using a quantization configuration\n",
    "\n",
    "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "we can significantly improve on the accuracy. We repeat the same exercise with the recommended configuration for quantizing for x86 architectures. This configuration does the following:\n",
    "1. Quantizes weights on a per-channel basis\n",
    "2. Uses a histogram observer that collects a histogram of activations and then picks quantization parameters in an optimal manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38310c7adec41539a0e04faec19562d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62802c7cbaa421bb331d7b449e1a2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052a56e2362c4426980c237520c50cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bb8ef79a7341cc829b3c2864e99f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "               batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(torchvision.datasets.MNIST('../data', train=False, \n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "              batch_size=64, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 model\n",
    "This code is taken from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py \n",
    "\n",
    "> NOTE: Training uses resnet model as is with addition operation and floating point inputs / outputs.      \n",
    "But when model is quantized while testing addition operation is replaced with FloatFunction and the inputs         / outputs are quantized/dequantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        groups: Number of blocked connections from input channels to output channels. Default: 1\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=3, with specified out_planes\n",
    "    \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=1, with specified out_planes\n",
    "        \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, quantize=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Notice the addition operation in both scenarios\n",
    "        if self.quantize:\n",
    "            out = self.skip_add.add(out, identity)\n",
    "        else:\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, mnist=False, quantize=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if mnist:\n",
    "            num_channels = 1\n",
    "        else:\n",
    "            num_channels = 3\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace \n",
    "            # the 2x2 stride with a dilated convolution instead.\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer, quantize=self.quantize))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer, quantize=self.quantize))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # Input are quantized\n",
    "        if self.quantize:\n",
    "            x = self.quant(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Outputs are dequantized\n",
    "        if self.quantize:\n",
    "            x = self.dequant(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "         # See note [TorchScript super()]\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\" Train the model with given dataset\n",
    "    \n",
    "    Args:\n",
    "        args: args like log interval\n",
    "        model: ResNet model to train\n",
    "        device: CPU/GPU\n",
    "        train_loader: dataset iterator\n",
    "        optimizer: optimizer to update weights\n",
    "        epoch: number of epochs to train for\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=-1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.621168\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.018376\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.013803\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.020921\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.046167\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.005177\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.012947\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.029640\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001139\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.001206\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    " \n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 500\n",
    "    save_model = True\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = ResNet(num_classes=10, mnist=True).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Print the size of the model.\n",
    "    \n",
    "    Args:\n",
    "        model: model whose size needs to be determined\n",
    "\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, quantize=False, fbgemm=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing with qauntization if quantize=True\n",
    "    if quantize:\n",
    "        modules_to_fuse = [['conv1', 'bn1'],\n",
    "                   ['layer1.0.conv1', 'layer1.0.bn1'],\n",
    "                   ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "                   ['layer1.1.conv1', 'layer1.1.bn1'],\n",
    "                   ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "                   ['layer2.0.conv1', 'layer2.0.bn1'],\n",
    "                   ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "                   ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
    "                   ['layer2.1.conv1', 'layer2.1.bn1'],\n",
    "                   ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "                   ['layer3.0.conv1', 'layer3.0.bn1'],\n",
    "                   ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "                   ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
    "                   ['layer3.1.conv1', 'layer3.1.bn1'],\n",
    "                   ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "                   ['layer4.0.conv1', 'layer4.0.bn1'],\n",
    "                   ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "                   ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
    "                   ['layer4.1.conv1', 'layer4.1.bn1'],\n",
    "                   ['layer4.1.conv2', 'layer4.1.bn2']]\n",
    "        model = torch.quantization.fuse_modules(model, modules_to_fuse)\n",
    "        if fbgemm:\n",
    "            model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        else:\n",
    "            model.qconfig = torch.quantization.default_qconfig\n",
    "        torch.quantization.prepare(model, inplace=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                model(data)\n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "    print(model)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            st = time.time()\n",
    "            output = model(data)\n",
    "            et = time.time()\n",
    "            test_loss += F.nll_loss(F.log_softmax(output, dim=-1), target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance - unquantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 44.759591\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 9928/10000 (99%)\n",
      "\n",
      "Elapsed time = 15.0568 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.11016496270895004, zero_point=61, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10224931687116623, zero_point=55, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10670270025730133, zero_point=67, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.1430341601371765, zero_point=48)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.11084137111902237, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10498251020908356, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.16973379254341125, zero_point=39)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.10595948249101639, zero_point=61, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1021081879734993, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.12286768108606339, zero_point=62)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.1736087203025818, zero_point=58)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.0999017134308815, zero_point=59, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09808696806430817, zero_point=66, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.15558238327503204, zero_point=37)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.10151470452547073, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08093071728944778, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.11250447481870651, zero_point=63)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.13991950452327728, zero_point=60)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08513453602790833, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08258720487356186, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.12554164230823517, zero_point=40)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.08223091065883636, zero_point=67, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08285616338253021, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.08519431203603745, zero_point=67)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.12057787925004959, zero_point=61)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08568473905324936, zero_point=66, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08993765711784363, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.12852446734905243, zero_point=42)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.2206566333770752, zero_point=35, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 11.201645\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 9926/10000 (99%)\n",
      "\n",
      "Elapsed time = 3.6423 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True, quantize=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader, quantize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
